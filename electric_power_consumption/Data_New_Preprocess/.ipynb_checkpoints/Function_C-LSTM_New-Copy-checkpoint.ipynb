{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49534bc4",
   "metadata": {},
   "source": [
    "# CNN+LSTM 전력 수요 예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a87c8",
   "metadata": {},
   "source": [
    "### <목차>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f886a9",
   "metadata": {},
   "source": [
    "### <화면 가로 확장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01779336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 화면 가로 확장 코드 (기본 width 50%)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914b761",
   "metadata": {},
   "source": [
    "### 1. 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fef1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, LSTM, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137a3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleGraph(title, plot, ylabel, savename):\n",
    "    plt.figure(figsize=(150,20))\n",
    "    plt.grid()\n",
    "    plt.title(title, fontsize=180)\n",
    "    plt.plot(plot)\n",
    "\n",
    "    plt.xlabel(\"Time by Hour\", fontsize=130)\n",
    "    plt.ylabel(ylabel, fontsize=130)\n",
    "    plt.margins(x=0.002)\n",
    "\n",
    "    plt.xticks(list_24, labels=np.arange(24))\n",
    "\n",
    "    plt.tick_params(axis='x', size=15)\n",
    "    plt.tick_params(axis='x', labelsize=70)\n",
    "    plt.tick_params(axis='y', size=15)\n",
    "    plt.tick_params(axis='y', labelsize=70)\n",
    "    plt.savefig(\"./Result/\"+savename+\".png\", bbox_inches='tight',pad_inches=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d96445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2102400 entries, 0 to 2102399\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   Year-Month-Date  object \n",
      " 2   Time             object \n",
      " 3   Holiday          int64  \n",
      " 4   Watt             float64\n",
      " 5   Temp('C)         float64\n",
      " 6   Humidity(%)      float64\n",
      " 7   CPI              float64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 128.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Data_4Y_Edited = pd.read_csv('./Combined_Data_New/House1_Ch1_Combined_Data_New_13-16_Outlier_Edited.csv', encoding='cp949')\n",
    "Data_4Y_Edited.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9811185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b1db7",
   "metadata": {},
   "source": [
    "### 편하게 학습하기 위한 함수(추후 본문 합류 및 삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3625badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Auto_Scaler_lr_filt_kernel_merge_case(scaler_name, lr, filt, kernel, mode, case):\n",
    "    start=datetime.datetime.now()\n",
    "    print(start, \"\\n\")\n",
    "    Data_4Y_Edited.sort_index(ascending=False).reset_index(drop=True)\n",
    "    from sklearn.preprocessing import PowerTransformer, QuantileTransformer, StandardScaler\n",
    "    scaler=scaler_name\n",
    "\n",
    "    scale_cols = [\"Holiday\", \"Watt\", \"Temp('C)\", \"Humidity(%)\", \"CPI\"]\n",
    "    Data_4Y_scaled = scaler.fit_transform(Data_4Y_Edited[scale_cols])\n",
    "    Data_4Y_scaled = pd.DataFrame(Data_4Y_scaled)\n",
    "    Data_4Y_scaled.columns = scale_cols\n",
    "    Data_4Y_scaled.insert(2, \"Watt2\", Data_4Y_scaled[\"Watt\"])\n",
    "    if case==1:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Watt2\"]]\n",
    "    if case==2:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Temp('C)\", \"Watt2\"]]\n",
    "    if case==3:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Humidity(%)\", \"Watt2\"]]\n",
    "    if case==4:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Humidity(%)\", \"Watt2\"]]\n",
    "    if case==5:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Temp('C)\", \"Humidity(%)\", \"Watt2\"]]\n",
    "    if case==6:\n",
    "        Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Temp('C)\", \"Humidity(%)\", \"Holiday\", \"Watt2\"]]\n",
    "    Data_4Y_scaled.info()\n",
    "    \n",
    "    #=================================================================================\n",
    "    TEST_SIZE = 1*60*24*365 #1년치를 테스트셋으로 사용\n",
    "    WINDOW_SIZE = 3\n",
    "    BATCH_SIZE = 32\n",
    "    VAL_DAYS = 525600\n",
    "\n",
    "    learning = Data_4Y_scaled[:-TEST_SIZE] # 학습에 쓰이는 전체 데이터\n",
    "    VAL_RATIO=VAL_DAYS/len(learning)\n",
    "    VAL_SIZE = int(len(learning)*VAL_RATIO)\n",
    "    TRAIN = learning[:-VAL_SIZE]\n",
    "    VAL = learning[-VAL_SIZE:]\n",
    "    TEST = Data_4Y_scaled[-(TEST_SIZE+WINDOW_SIZE):]\n",
    "\n",
    "    train_data = windowed_dataset(TRAIN, WINDOW_SIZE, BATCH_SIZE, False) \n",
    "    valid_data = windowed_dataset(VAL, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "    test_data = windowed_dataset(TEST, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "\n",
    "    #===========================================================================\n",
    "    LeakyReLU=tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=filt, kernel_size=kernel, padding=\"causal\", activation=LeakyReLU, input_shape=[WINDOW_SIZE, TRAIN.shape[1]]),\n",
    "        MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "        Conv1D(filters=filt, kernel_size=kernel, padding=\"causal\", activation=LeakyReLU),\n",
    "        MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "        Bidirectional(LSTM(4, activation=LeakyReLU, return_sequences=True), merge_mode=mode),\n",
    "        TimeDistributed(Dense(8)),\n",
    "        Bidirectional(LSTM(4, activation=LeakyReLU, return_sequences=True), merge_mode=mode),\n",
    "        TimeDistributed(Dense(4)),\n",
    "        Bidirectional(LSTM(2, activation=LeakyReLU, return_sequences=False), merge_mode=mode),\n",
    "        Dense(1)\n",
    "                        ])\n",
    "    Nadam = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=Nadam)\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    with tf.device('/GPU:0'):\n",
    "        model_path = 'model'\n",
    "        filename = os.path.join(model_path, \"tmp_checkpoint_CL_\"+str(scaler_name)+\"_\"+str(lr)+\"_\"+str(filt)+\"_\"+str(kernel)+\"_\"+mode+\"_\"+str(case)+\".h5\")\n",
    "        checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        history = model.fit(train_data, epochs=20, batch_size=BATCH_SIZE, validation_data=(valid_data), callbacks=[checkpoint, early_stop])\n",
    "\n",
    "    model.load_weights(filename)\n",
    "    pred = model.predict(test_data)\n",
    "    pred.shape\n",
    "    #================================================================================================================\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title('Model Loss Convergence Graph', size='15')\n",
    "    y_tloss = history.history['loss']\n",
    "    y_vloss = history.history['val_loss']\n",
    "    x_len = np.arange(len(y_tloss))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.xticks(range(0,50,10), labels=range(1,21, 10))\n",
    "\n",
    "    plt.plot(x_len, y_tloss, \"o-\", c=\"blue\", markersize=3)\n",
    "    plt.plot(x_len, y_vloss, \"o-\", c=\"red\", markersize=3)\n",
    "    plt.margins(x=0.02)\n",
    "    plt.legend(['Training loss', 'Validation loss'])\n",
    "    plt.savefig(\"./Result/CNN+LSTM/Graph/Model_Loss_Convergence_Graph_\"+str(scaler_name)+\"_\"+str(lr)+\"_\"+str(filt)+\"_\"+str(kernel)+\"_\"+mode+\"_\"+str(case)+\".png\")\n",
    "\n",
    "    #=================================================================================================================\n",
    "    fig = plt.figure(figsize=(300,15)) \n",
    "    ax1 = fig.add_subplot() # subplot 그래프 생성\n",
    "    ax1.tick_params(axis='y', size=20, labelsize=20) # y축 눈금 표기 설정\n",
    "    plt.yticks([0, 0.111, 0.222, 0.333, 0.444, 0.555, 0.666, 0.777, 0.888, 1.0], \n",
    "               labels=['0', '1000 W', '2000 W', '3000 W', '4000 W', '5000 W', '6000 W', '7000 W', '8000 W','9000 W'])\n",
    "\n",
    "    color1 = 'darkorange'\n",
    "    ax1.plot(TEST['Watt'][:-WINDOW_SIZE], color=color1)\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.tick_params(axis='x', size=20, labelsize=20)\n",
    "    ax1.margins(x=0.005)\n",
    "\n",
    "    ax1.legend(['Actual'], loc=1, bbox_to_anchor=(0.995, 1, 0, 0))\n",
    "\n",
    "    color2 = 'blue'\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(pred, color=color2)\n",
    "    ax2.tick_params(axis='x', size=20, labelsize=20)\n",
    "    ax2.margins(x=0.005)\n",
    "\n",
    "    ax2.legend(['Predict'], loc=1, bbox_to_anchor=(1, 1, 0, 0))\n",
    "\n",
    "    plt.savefig(\"./Result/CNN+LSTM/Graph/Pred_with_Actual_\"+str(scaler_name)+\"_\"+str(lr)+\"_\"+str(filt)+\"_\"+str(kernel)+\"_\"+mode+\"_\"+str(case)+\".png\")\n",
    "    \n",
    "    from sklearn.metrics import r2_score as r2\n",
    "    from sklearn.metrics import mean_absolute_error as MAE\n",
    "    from sklearn.metrics import mean_squared_error as MSE\n",
    "    def SMAPE(y_test, y_pred):\n",
    "        return np.mean((np.abs(y_test-y_pred))/(np.abs(y_test)+np.abs(y_pred)))*100/2\n",
    "    \n",
    "    true = TEST['Watt'][:-WINDOW_SIZE].to_numpy()\n",
    "    true = true.reshape(-1,1)\n",
    "\n",
    "    MAE = MAE(true, pred)\n",
    "    RMSE = np.sqrt(MSE(true, pred))\n",
    "    SMAPE0 = SMAPE(true, pred)\n",
    "    \n",
    "    print('\\nr2 >> %.4f' %r2(true, pred)) # 1에 가까워야 좋음\n",
    "    print('MAE >> %.4f' %MAE) # 0에 가까워야 좋음\n",
    "    print('RMSE >> %.4f' %RMSE) # 0에 가까워야 좋음\n",
    "    print('SMAPE >> %.4f' %SMAPE0) # 0에 가까워야 좋음\n",
    "    end=datetime.datetime.now()\n",
    "    print(\"\\n소요시간 >>\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 12:01:47.635461\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2102400 entries, 0 to 2102399\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   Watt         float64\n",
      " 1   Temp('C)     float64\n",
      " 2   Humidity(%)  float64\n",
      " 3   Holiday      float64\n",
      " 4   Watt2        float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 80.2 MB\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/20\n",
      "    228/Unknown - 26s 86ms/step - loss: 0.3810"
     ]
    }
   ],
   "source": [
    "Auto_Scaler_lr_filt_kernel_merge_case(QuantileTransformer(), 0.0003, 8, 4, \"ave\", 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
