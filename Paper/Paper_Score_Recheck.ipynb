{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4e98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, LSTM, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7831ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2102400 entries, 0 to 2102399\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   Year-Month-Date  object \n",
      " 2   Time             object \n",
      " 3   Holiday          int64  \n",
      " 4   Watt             float64\n",
      " 5   Temp('C)         float64\n",
      " 6   Humidity(%)      float64\n",
      " 7   CPI              float64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 128.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Data_4Y_Edited = pd.read_csv('./House1_Ch1_Combined_Data_New_13-16_Outlier_Edited.csv', encoding='cp949')\n",
    "Data_4Y_Edited.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d594dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2102400 entries, 0 to 2102399\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Watt    float64\n",
      " 1   Watt2   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 32.1 MB\n"
     ]
    }
   ],
   "source": [
    "Data_4Y_Edited.sort_index(ascending=False).reset_index(drop=True)\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer, StandardScaler\n",
    "scaler=MinMaxScaler()\n",
    "Scaler_Name=str(scaler)[:-2]\n",
    "\n",
    "#scale_cols = [\"Holiday\", \"Watt\", \"Temp('C)\", \"Humidity(%)\", \"CPI\"]\n",
    "Data_4Y_Edited.insert(2, \"Watt2\", Data_4Y_Edited[\"Watt\"])\n",
    "scale_cols = [\"Watt\", \"Watt2\"]\n",
    "Data_4Y_scaled = scaler.fit_transform(Data_4Y_Edited[scale_cols])\n",
    "Data_4Y_scaled = pd.DataFrame(Data_4Y_scaled)\n",
    "Data_4Y_scaled.columns = scale_cols\n",
    "\n",
    "#Data_4Y_scaled=Data_4Y_scaled[[\"Watt\", \"Watt2\"]]\n",
    "Data_4Y_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b56efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1=MinMaxScaler()\n",
    "Data_4Y_Edited[\"Watt\"]=scaler1.fit_transform(Data_4Y_Edited[\"Watt\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572ca9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 1*60*24*365 #1년치를 테스트셋으로 사용\n",
    "WINDOW_SIZE = 5 #얼마 동안의 과거 기반의 데이터로 다음값을 예측할 것인지 설정. \n",
    "BATCH_SIZE = 64\n",
    "VAL_DAYS = 525600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a718589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051200 525600 525600\n"
     ]
    }
   ],
   "source": [
    "learning = Data_4Y_scaled[:-TEST_SIZE] # 학습에 쓰이는 전체 데이터\n",
    "VAL_RATIO=VAL_DAYS/len(learning)\n",
    "VAL_SIZE = int(len(learning)*VAL_RATIO)\n",
    "TRAIN = learning[:-VAL_SIZE]\n",
    "VAL = learning[-VAL_SIZE:]\n",
    "TEST = Data_4Y_scaled[-TEST_SIZE:]\n",
    "print(len(TRAIN), len(VAL), len(TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3eae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd8d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = windowed_dataset(TRAIN, WINDOW_SIZE, BATCH_SIZE, False) \n",
    "valid_data = windowed_dataset(VAL, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "test_data = windowed_dataset(TEST, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05de2024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 8)              72        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 8)             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 8)              264       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 5, 8)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 4)             416       \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 5, 8)             40        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 4)             416       \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 5, 4)             20        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 2)                112       \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,343\n",
      "Trainable params: 1,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeakyReLU=tf.keras.layers.LeakyReLU(alpha=0.3)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=8, kernel_size=4, padding=\"causal\", activation=LeakyReLU, input_shape=[WINDOW_SIZE, TRAIN.shape[1]]),\n",
    "    MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "    Conv1D(filters=8, kernel_size=4, padding=\"causal\", activation=LeakyReLU),\n",
    "    MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "    Bidirectional(LSTM(4, activation=LeakyReLU, return_sequences=True), merge_mode=\"sum\"),\n",
    "    TimeDistributed(Dense(8)),\n",
    "    Bidirectional(LSTM(4, activation=LeakyReLU, return_sequences=True), merge_mode=\"sum\"),\n",
    "    TimeDistributed(Dense(4)),\n",
    "    Bidirectional(LSTM(2, activation=LeakyReLU, return_sequences=False), merge_mode=\"sum\"),\n",
    "    Dense(1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "Nadam = tf.keras.optimizers.Nadam(learning_rate=0.0003)\n",
    "model.compile(loss='mean_absolute_error', optimizer=Nadam)\n",
    "print('\\n'*4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7977c04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525595, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./Data/MinMax_LReLU.h5\"\n",
    "model.load_weights(filename)\n",
    "pred = model.predict(test_data)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77dc4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inversed_pred = scaler1.inverse_transform(np.array(pred).reshape(-1,1))\n",
    "Inversed_true = scaler1.inverse_transform(np.array(TEST['Watt'][:-WINDOW_SIZE]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7092ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))\n",
    "\n",
    "def smape(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean((np.abs(y_test-y_pred))/(np.abs(y_test)+np.abs(y_pred)))*100/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff5532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true = TEST['Watt2'][:-WINDOW_SIZE].to_numpy()\n",
    "#true = true.reshape(-1,1)\n",
    "\n",
    "RMSE = np.sqrt(MSE(Inversed_true, Inversed_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f7084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 >> -0.3940\n",
      "MAE >> 260.3021\n",
      "RMSE >> 637.8751\n",
      "SMAPE >> 9.3031\n"
     ]
    }
   ],
   "source": [
    "print('r2 >> %.4f' %r2(Inversed_true, Inversed_pred)) # 1에 가까워야 좋음\n",
    "print('MAE >> %.4f' %mae(Inversed_true, Inversed_pred)) # 0에 가까워야 좋음\n",
    "print('RMSE >> %.4f' %RMSE) # 0에 가까워야 좋음\n",
    "print('SMAPE >> %.4f' %smape(Inversed_true, Inversed_pred)) # 0에 가까워야 좋음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
